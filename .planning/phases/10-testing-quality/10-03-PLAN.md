---
phase: 10-testing-quality
plan: 03
type: execute
wave: 2
depends_on: ["10-01", "10-02"]
files_modified:
  - tests/load/test_concurrent_sessions.py
  - tests/load/test_rate_limiting.py
  - tests/chaos/test_network_resilience.py
  - tests/chaos/test_crash_recovery.py
autonomous: true

must_haves:
  truths:
    - "System handles 100+ concurrent sessions without degradation"
    - "Rate limiting prevents API errors under sustained message bursts"
    - "Network drops trigger automatic reconnection without data loss"
    - "Session state recovers correctly after daemon crashes"
  artifacts:
    - path: "tests/load/test_concurrent_sessions.py"
      provides: "Concurrent load tests for session management"
      min_lines: 80
      exports: ["test_100_concurrent_sessions", "test_session_isolation"]
    - path: "tests/load/test_rate_limiting.py"
      provides: "Rate limiter stress tests"
      min_lines: 60
      exports: ["test_burst_handling", "test_sustained_load"]
    - path: "tests/chaos/test_network_resilience.py"
      provides: "Network failure chaos tests"
      min_lines: 70
      exports: ["test_websocket_drop", "test_message_buffer_drain"]
    - path: "tests/chaos/test_crash_recovery.py"
      provides: "Process crash recovery tests"
      min_lines: 60
      exports: ["test_daemon_crash_recovery", "test_corrupt_state_recovery"]
  key_links:
    - from: "test_concurrent_sessions.py"
      to: "SessionManager"
      via: "parallel session creation with asyncio.gather"
      pattern: "asyncio.gather.*create_session"
    - from: "test_rate_limiting.py"
      to: "RateLimiter + MessageQueue"
      via: "burst message submission"
      pattern: "rate_limiter.*send_message"
    - from: "test_network_resilience.py"
      to: "ReconnectionManager + MessageBuffer"
      via: "simulated WebSocket disconnect"
      pattern: "reconnection_manager.*on_disconnect"
---

<objective>
Implement load testing and chaos testing to validate system reliability under stress and failure conditions.

Purpose: Ensure the system handles edge cases, concurrent load, and failure scenarios gracefully. Load tests validate performance, chaos tests validate resilience.

Output: Load and chaos test suites proving the system meets reliability requirements under adverse conditions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md

# Phase 10 requirements this plan addresses:
# - TEST-03: Tests validate rate limiting and message queue behavior under load
# - TEST-04: Tests verify session persistence and crash recovery scenarios
# - TEST-05: Tests simulate network drops and verify reconnection behavior

# Components under stress/chaos testing:
@src/session/manager.py
@src/signal/rate_limiter.py
@src/signal/message_buffer.py
@src/signal/reconnection.py
@src/session/recovery.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement concurrent session load tests</name>
  <files>tests/load/test_concurrent_sessions.py</files>
  <action>
    Create load tests for session management:
    1. Create directory: `mkdir -p tests/load`
    2. `test_100_concurrent_sessions()`:
       - Create 100 temp project directories
       - Use asyncio.gather to create 100 sessions in parallel
       - Verify all sessions created successfully (no race conditions)
       - Verify SQLite WAL mode handles concurrent writes
       - Send command to random session
       - Verify correct session receives command (no cross-talk)
       - Clean up all 100 sessions
    3. `test_session_isolation_under_load()`:
       - Create 10 sessions
       - Send different commands to each in parallel
       - Verify each session maintains independent state
       - Verify no shared mutable state causes bugs
    4. `test_database_contention()`:
       - Simulate 50 concurrent session state updates
       - Verify no SQLite locking errors
       - Verify all updates committed correctly

    Use pytest-asyncio for async test execution. Assert no errors, timeouts, or state corruption.
  </action>
  <verify>
    - `pytest tests/load/test_concurrent_sessions.py -v` passes
    - Tests complete in <30 seconds (performance baseline)
    - No SQLite locking errors logged
  </verify>
  <done>Concurrent session load tests pass with 100+ sessions</done>
</task>

<task type="auto">
  <name>Task 2: Implement rate limiting stress tests</name>
  <files>tests/load/test_rate_limiting.py</files>
  <action>
    Create rate limiter stress tests:
    1. `test_burst_handling()`:
       - Create RateLimiter with 30 msg/min, 5 burst
       - Submit 10 messages rapidly (exceeds burst allowance)
       - Verify first 5 sent immediately
       - Verify remaining 5 queued
       - Advance time by 10 seconds
       - Verify queued messages drain at controlled rate
    2. `test_sustained_high_load()`:
       - Submit 100 messages over 2 minutes
       - Verify rate limiter prevents 413 errors
       - Verify all messages eventually sent
       - Verify no message loss
    3. `test_exponential_backoff_on_rejection()`:
       - Mock Signal API returning 429 Too Many Requests
       - Verify rate limiter triggers backoff
       - Verify retry delay: 1s → 2s → 4s → ... → 60s max
       - Verify messages not dropped during backoff
    4. `test_queue_overflow_handling()`:
       - Set queue max_size=10
       - Submit 20 messages
       - Verify oldest messages dropped (FIFO eviction)
       - Verify warning logged

    Use real RateLimiter + MessageQueue, mock Signal API responses.
  </action>
  <verify>
    - `pytest tests/load/test_rate_limiting.py -v` passes
    - Tests verify no 413 rate limit errors occur
    - Backoff timing verified with time assertions
  </verify>
  <done>Rate limiting stress tests validate queue and backoff behavior</done>
</task>

<task type="auto">
  <name>Task 3: Implement network resilience chaos tests</name>
  <files>tests/chaos/test_network_resilience.py</files>
  <action>
    Create chaos tests for network failures:
    1. Create directory: `mkdir -p tests/chaos`
    2. `test_websocket_drop_and_reconnect()`:
       - Establish WebSocket connection to signal-cli-rest-api (mocked)
       - Start receiving messages
       - Simulate network drop (close WebSocket)
       - Verify ReconnectionManager detects DISCONNECTED state
       - Verify auto_reconnect() task spawned
       - Verify exponential backoff: 1s, 2s, 4s, 8s
       - Mock successful reconnection
       - Verify state transitions: DISCONNECTED → RECONNECTING → CONNECTED
    3. `test_message_buffer_during_disconnect()`:
       - Start CONNECTED, fill MessageBuffer with 50 messages
       - Trigger disconnect
       - Attempt to send 10 more messages
       - Verify messages buffered (not lost)
       - Reconnect
       - Verify buffer drains on reconnect
       - Verify all 60 messages eventually sent
    4. `test_session_sync_after_reconnect()`:
       - Session ACTIVE before disconnect
       - Disconnect for 5 minutes (simulated)
       - Claude executes commands during disconnect (activity_log grows)
       - Reconnect
       - Verify catch-up summary generated
       - Verify activity_log sent to user
       - Verify session state synchronized

    Use real ReconnectionManager + MessageBuffer, mock WebSocket lifecycle.
  </action>
  <verify>
    - `pytest tests/chaos/test_network_resilience.py -v` passes
    - Tests verify no message loss during disconnects
    - Reconnection timing verified with backoff assertions
  </verify>
  <done>Network resilience chaos tests validate reconnection and buffering</done>
</task>

<task type="auto">
  <name>Task 4: Implement crash recovery chaos tests</name>
  <files>tests/chaos/test_crash_recovery.py</files>
  <action>
    Create chaos tests for daemon/process crashes:
    1. `test_daemon_crash_recovery()`:
       - Create 3 ACTIVE sessions in database
       - Simulate daemon crash (no graceful shutdown)
       - Restart daemon (recovery.recover() runs)
       - Verify all 3 sessions transitioned to CRASHED
       - Verify recovered_at timestamp set
       - Verify user notifications sent (mocked)
    2. `test_corrupt_state_recovery()`:
       - Create session with invalid state (e.g., status="INVALID")
       - Run recovery logic
       - Verify graceful handling (log error, mark as CRASHED)
       - Verify no exception crashes daemon startup
    3. `test_process_kill_during_command()`:
       - Session executing Claude command
       - Kill ClaudeProcess (SIGKILL)
       - Verify process.wait() detects termination
       - Verify session marked as CRASHED
       - Verify error notification sent
    4. `test_sqlite_corruption_recovery()`:
       - Create sessions.db with valid data
       - Corrupt database file (write garbage bytes)
       - Attempt daemon startup
       - Verify graceful degradation (log error, notify user)
       - Suggest recovery: delete corrupt DB, restart fresh

    Use real SessionManager + CrashRecovery, mock notifications. Test boundary conditions.
  </action>
  <verify>
    - `pytest tests/chaos/test_crash_recovery.py -v` passes
    - Tests verify crash detection and state recovery
    - Corrupt state handled without daemon crash
  </verify>
  <done>Crash recovery chaos tests validate resilience to failures</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pytest tests/load/ -v` passes all load tests
- [ ] `pytest tests/chaos/ -v` passes all chaos tests
- [ ] Load tests demonstrate system handles 100+ concurrent sessions
- [ ] Chaos tests prove resilience to network drops and crashes
</verification>

<success_criteria>
- All tasks completed
- Load tests validate concurrent session handling and rate limiting
- Chaos tests validate network resilience and crash recovery
- System proven reliable under stress and failure conditions
- Foundation for performance regression testing established
</success_criteria>

<output>
After completion, create `.planning/phases/10-testing-quality/10-03-SUMMARY.md`
</output>
