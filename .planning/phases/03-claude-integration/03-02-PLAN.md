---
phase: 03-claude-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [src/claude/parser.py, tests/test_claude_parser.py]
autonomous: true

must_haves:
  truths:
    - "Tool calls extracted from Claude output (Read, Edit, Write, Bash)"
    - "Progress messages identified ('Analyzing code...', 'Writing file...')"
    - "Error messages detected ('Failed to read file')"
  artifacts:
    - path: "src/claude/parser.py"
      provides: "OutputParser for Claude Code CLI output"
      min_lines: 80
      exports: ["OutputParser", "OutputType", "ParsedOutput"]
    - path: "tests/test_claude_parser.py"
      provides: "Tests for output parsing logic"
      contains: "test_parse_tool_call"
  key_links:
    - from: "OutputParser.parse()"
      to: "OutputType enum"
      via: "pattern matching"
      pattern: "OutputType\\."
---

<objective>
Parse Claude Code CLI output into structured events

Purpose: Convert raw CLI text into typed events (tool calls, progress, errors) for Signal display
Output: OutputParser that classifies and extracts data from Claude output
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 3 requirement details
CLDE-04: Tool calls stream in real-time
CLDE-05: Progress updates show action
CLDE-06: Error messages display

# Claude Code output format examples (from documentation/manual testing)
# Tool calls: "Using Read tool on src/main.py"
# Progress: "Analyzing codebase..."
# Errors: "Error: Failed to read file"
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create OutputParser with pattern matching (TDD RED-GREEN-REFACTOR)</name>
  <files>tests/test_claude_parser.py, src/claude/parser.py</files>
  <action>
**RED**: Write failing tests:
- test_parse_tool_call_read(): "Using Read tool on file.py" → ToolCall(tool="Read", target="file.py")
- test_parse_tool_call_edit(): "Using Edit tool on file.py" → ToolCall(tool="Edit", target="file.py")
- test_parse_tool_call_bash(): "Running: ls -la" → ToolCall(tool="Bash", command="ls -la")
- test_parse_progress(): "Analyzing code..." → Progress(message="Analyzing code...")
- test_parse_error(): "Error: Failed" → Error(message="Failed")
- test_parse_response(): Regular text → Response(text="...")

**GREEN**: Implement OutputParser:
- Define OutputType enum: TOOL_CALL, PROGRESS, ERROR, RESPONSE
- Define dataclasses: ToolCall, Progress, Error, Response (all inherit ParsedOutput)
- parse(line: str) -> ParsedOutput:
  - Match "Using (Read|Edit|Write|Grep|Glob) tool" → ToolCall
  - Match "Running: " → ToolCall(tool="Bash")
  - Match "Error: " → Error
  - Match progress patterns ("Analyzing", "Writing", "Reading") → Progress
  - Default → Response

Use regex for pattern matching. Return typed dataclasses for each output type.

**REFACTOR**: Extract regex patterns to constants if repetitive.

**TDD Strategy**: Write test → run (fails) → implement → run (passes) → refactor → commit each phase
  </action>
  <verify>pytest tests/test_claude_parser.py -v passes</verify>
  <done>OutputParser classifies Claude output into ToolCall, Progress, Error, Response types</done>
</task>

<task type="auto">
  <name>Task 2: Add streaming parser for multi-line responses</name>
  <files>src/claude/parser.py</files>
  <action>
Add StreamingParser class (standard implementation - no TDD needed for simple wrapper):
- __init__(): Initialize OutputParser and line buffer
- feed(chunk: str): Split by newlines, buffer incomplete lines
- parse_buffered(): For each complete line, call OutputParser.parse(), yield results
- flush(): Parse remaining buffer as final message

Handles case where Claude response spans multiple lines or arrives in chunks.
  </action>
  <verify>pytest tests/test_claude_parser.py -v passes (add test for streaming)</verify>
  <done>StreamingParser handles chunked input and multi-line responses</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] pytest tests/test_claude_parser.py -v passes
- [ ] All OutputType variants tested
- [ ] git log shows TDD pattern (test → feat)
- [ ] Parser handles tool calls, progress, errors, responses
</verification>

<success_criteria>

- All tests pass
- TDD commits present for core parsing logic
- OutputParser extracts structured data from Claude output
- StreamingParser handles chunked input
</success_criteria>

<output>
After completion, create `.planning/phases/03-claude-integration/03-02-SUMMARY.md`
</output>
